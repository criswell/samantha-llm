#!/usr/bin/env python3
"""
samantha-llm - Installation and management script for Samantha Hartwell LLM

Cross-platform installer supporting Linux, macOS, and Windows.
Version: 0.3.0
"""

import argparse
import json
import os
import platform
import shutil
import subprocess
import sys
import time
from pathlib import Path
from datetime import datetime


# Filename
FILENAME = os.path.basename(__file__)

# Version
VERSION = "0.5.0"

# Subconscious analysis prompt template
ANALYSIS_PROMPT_TEMPLATE = """You are analyzing a terminal recording of a conversation between a user and an AI coding assistant (Claude, Copilot, or Abacus.ai). Your goal is to extract meaningful insights that will help the AI assistant better understand the user's work patterns, preferences, and context in future sessions.

The conversation text has been cleaned of ANSI codes and formatting, but preserves the actual dialogue and actions taken.

## Your Task

Analyze the conversation and extract insights in the following categories:

### 1. Patterns
Identify recurring workflows, common tasks, or repeated behaviors. Examples:
- "User frequently uses Task tool to track multi-step work"
- "User prefers to review plans before implementation"
- "User often asks for multiple options before deciding"

### 2. Decisions
Document architectural choices, technical decisions, and trade-offs discussed. Include rationale when available. Examples:
- "Decided to use JSON over YAML for config (better programmatic access)"
- "Chose to implement Claude first, then adapt to other agents (validate quality before compatibility)"
- "Opted for plain text parsing over JSON schema (works across all agents)"

### 3. TODOs
Extract action items, follow-ups, or deferred work mentioned during the conversation. Examples:
- "Test subconscious worker with real terminal recordings"
- "Add Abacus analyzer after Claude is working"
- "Consider extracting bricklayer into separate package (Q2 2026)"

### 4. Preferences
Identify the user's working style, preferences, or dislikes. Examples:
- "User prefers starting with simple solutions before optimizing"
- "User values thorough research and analysis before implementation"
- "User likes having escape hatches (e.g., reset commands for customizations)"

### 5. Learnings
Capture new knowledge, discoveries, or insights gained during the session. Examples:
- "Discovered that Copilot doesn't support JSON output, only plain text"
- "Learned that each LLM has different permission models (tool-based vs path-based)"
- "Found that terminal recordings can be parsed to extract session metadata"

## Output Format

Provide your analysis in the following structured markdown format:

```markdown
# Conversation Analysis

## Patterns
- [Pattern description]
- [Pattern description]

## Decisions
- [Decision]: [Rationale]
- [Decision]: [Rationale]

## TODOs
- [ ] [Action item]
- [ ] [Action item]

## Preferences
- [Preference]: [Context]
- [Preference]: [Context]

## Learnings
- [Learning]: [Details]
- [Learning]: [Details]

## Summary
[2-3 sentence summary of the session and its significance]
```

## Guidelines

- Be concise but specific
- Focus on insights that would be useful in future sessions
- If a category has no relevant items, write "None identified" instead of leaving it empty
- Prioritize quality over quantity (3-5 good items per category is better than 10 mediocre ones)
- Include enough context so the insights make sense without reading the full conversation
- For technical decisions, capture the "why" not just the "what"

## The Conversation to Analyze

The terminal recording text follows below. Remember: extract insights, not a transcript.

---
"""

# ANSI color codes
class Colors:
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[1;33m'
    BLUE = '\033[0;34m'
    NC = '\033[0m'  # No Color

    @classmethod
    def supports_color(cls):
        """Check if terminal supports color"""
        if platform.system() == 'Windows':
            # Windows 10+ supports ANSI colors with VT100 emulation
            return True
        return hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()


def print_info(message):
    """Print info message"""
    if Colors.supports_color():
        print(f"{Colors.BLUE}[INFO]{Colors.NC} {message}")
    else:
        print(f"[INFO] {message}")


def print_success(message):
    """Print success message"""
    if Colors.supports_color():
        print(f"{Colors.GREEN}[SUCCESS]{Colors.NC} {message}")
    else:
        print(f"[SUCCESS] {message}")


def print_warning(message):
    """Print warning message"""
    if Colors.supports_color():
        print(f"{Colors.YELLOW}[WARNING]{Colors.NC} {message}")
    else:
        print(f"[WARNING] {message}")


def print_error(message):
    """Print error message"""
    if Colors.supports_color():
        print(f"{Colors.RED}[ERROR]{Colors.NC} {message}")
    else:
        print(f"[ERROR] {message}")


def get_platform():
    """Get platform name (linux, darwin, windows)"""
    return platform.system().lower()


def get_install_dir():
    """Get platform-appropriate install directory"""
    system = get_platform()
    if system == 'windows':
        return Path(os.environ['LOCALAPPDATA']) / 'Programs' / 'samantha-llm'
    else:  # Linux, Darwin (macOS)
        return Path.home() / '.local' / 'bin'


def get_config_dir():
    """Get platform-appropriate config directory"""
    system = get_platform()
    if system == 'windows':
        return Path(os.environ['APPDATA']) / 'samantha-llm'
    else:  # Linux, Darwin (macOS)
        return Path.home() / '.config' / 'samantha-llm'


def get_script_name():
    """Get platform-appropriate script name"""
    system = get_platform()
    if system == 'windows':
        return 'samantha-llm.bat'
    else:
        return 'samantha-llm'


def get_repo_dir():
    """Get the samantha-llm repository directory"""
    # This script should be in the root of the repo
    return Path(__file__).resolve().parent


def get_config_file():
    """Get config file path"""
    return get_config_dir() / 'config.json'


def get_old_config_file():
    """Get old config file path (for migration)"""
    return get_config_dir() / 'config'


def read_config():
    """Read JSON config file"""
    config_file = get_config_file()
    if not config_file.exists():
        return None

    try:
        with open(config_file, 'r') as f:
            return json.load(f)
    except Exception as e:
        print_error(f"Failed to read config: {e}")
        return None


def write_config(config):
    """Write JSON config file"""
    config_file = get_config_file()
    config_dir = get_config_dir()

    # Create config directory if needed
    config_dir.mkdir(parents=True, exist_ok=True)

    try:
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2)
        return True
    except Exception as e:
        print_error(f"Failed to write config: {e}")
        return False


def migrate_old_config():
    """Migrate old shell-style config to JSON"""
    old_config_file = get_old_config_file()
    new_config_file = get_config_file()

    # Check if old config exists and new doesn't
    if not old_config_file.exists() or new_config_file.exists():
        return False

    print_info("Migrating old config to JSON format...")

    # Parse old config
    try:
        old_config = {}
        for line in old_config_file.read_text().splitlines():
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                old_config[key] = value.strip('"')

        # Create new JSON config
        new_config = {
            'version': old_config.get('SAMANTHA_VERSION', VERSION),
            'platform': old_config.get('SAMANTHA_PLATFORM', get_platform()),
            'repo_path': old_config.get('SAMANTHA_REPO_PATH', str(get_repo_dir())),
            'agents': {},
            'workspaces': {}
        }

        # Write new config
        if write_config(new_config):
            # Backup old config
            backup_file = old_config_file.with_suffix('.backup')
            shutil.copy2(old_config_file, backup_file)
            print_success(f"Config migrated successfully!")
            print_info(f"  Old config backed up to: {backup_file}")
            print_info(f"  New config: {new_config_file}")
            return True
        else:
            return False

    except Exception as e:
        print_error(f"Config migration failed: {e}")
        return False


def migrate_to_v050(config):
    """
    Migrate config to v0.5.0 (persona system)

    Returns:
        Updated config dict
    """
    if config.get('version', '0.0.0') >= '0.5.0':
        return config  # Already migrated

    print_info("Migrating config to v0.5.0 (persona system)...")

    # Add personas section if missing
    if 'personas' not in config:
        config['personas'] = {}

    # Register samantha-hartwell as builtin if not already registered
    if 'samantha-hartwell' not in config['personas']:
        config['personas']['samantha-hartwell'] = {
            'type': 'builtin',
            'file': 'persona/main.md',
            'description': 'Software engineer with 30+ years experience',
            'official': True
        }

    # Set default persona if not set
    if 'default_persona' not in config:
        config['default_persona'] = 'samantha-hartwell'

    # Update version
    config['version'] = '0.5.0'

    print_success("Config migrated to v0.5.0!")

    return config


def ensure_config_migrated():
    """Ensure config is migrated to latest version"""
    config = read_config()

    if not config:
        return None

    # Check if migration needed
    if config.get('version', '0.0.0') < '0.5.0':
        config = migrate_to_v050(config)
        write_config(config)

    return config


def get_install_path():
    """Get full install path"""
    return get_install_dir() / get_script_name()


def is_installed():
    """Check if samantha-llm is installed"""
    install_path = get_install_path()
    config_file = get_config_file()

    system = get_platform()
    if system == 'windows':
        # On Windows, check if .bat file exists and config exists
        return install_path.exists() and config_file.exists()
    else:
        # On Unix, check if symlink exists and config exists
        return install_path.is_symlink() and config_file.exists()


def check_path():
    """Check if install directory is in PATH"""
    install_dir = str(get_install_dir())
    path_env = os.environ.get('PATH', '')

    if platform.system() == 'Windows':
        # Windows is case-insensitive and uses ; as separator
        paths = [p.lower() for p in path_env.split(';')]
        return install_dir.lower() in paths
    else:
        # Unix uses : as separator
        return install_dir in path_env.split(':')


def create_config():
    """Create JSON config file"""
    repo_dir = get_repo_dir()

    print_info(f"Creating config file: {get_config_file()}")

    config = {
        'version': VERSION,
        'platform': get_platform(),
        'repo_path': str(repo_dir),
        'default_persona': 'samantha-hartwell',
        'personas': {
            'samantha-hartwell': {
                'type': 'builtin',
                'file': 'persona/main.md',
                'description': 'Software engineer with 30+ years experience',
                'official': True
            }
        },
        'agents': {},
        'workspaces': {}
    }

    return write_config(config)


def get_personas_dir():
    """Get personas directory path"""
    return get_config_dir() / 'personas'


def get_persona_path(persona_name, config=None):
    """
    Resolve persona file path based on type (builtin vs custom)

    Args:
        persona_name: Name of the persona
        config: Config dict (will read if not provided)

    Returns:
        Path to persona file
    """
    if config is None:
        config = read_config()

    if not config or 'personas' not in config:
        return None

    if persona_name not in config['personas']:
        return None

    persona = config['personas'][persona_name]

    if persona['type'] == 'builtin':
        # Read from repo (version controlled)
        repo_path = Path(config['repo_path'])
        return repo_path / persona['file']
    else:  # custom
        # Read from config directory (user managed)
        return Path(persona['file']).expanduser()


def list_personas(config=None):
    """
    List all registered personas

    Returns:
        List of (name, persona_dict) tuples sorted by type (builtin first)
    """
    if config is None:
        config = read_config()

    if not config or 'personas' not in config:
        return []

    personas = config['personas'].items()

    # Sort: builtins first, then alphabetically within each group
    def sort_key(item):
        name, persona = item
        is_builtin = persona.get('type') == 'builtin'
        return (not is_builtin, name)

    return sorted(personas, key=sort_key)


def validate_persona_name(name):
    """
    Validate persona name (alphanumeric, hyphens, underscores only)

    Returns:
        (is_valid, error_message)
    """
    import re
    if not name:
        return False, "Persona name cannot be empty"

    if not re.match(r'^[a-z0-9_-]+$', name):
        return False, "Persona name must contain only lowercase letters, numbers, hyphens, and underscores"

    if len(name) > 50:
        return False, "Persona name must be 50 characters or less"

    return True, None


def generate_bootstrap_prompt(persona_name, config=None):
    """
    Generate bootstrap prompt with selected persona injected

    Args:
        persona_name: Name of the persona to use
        config: Config dict (will read if not provided)

    Returns:
        Full bootstrap prompt as string, or None if error
    """
    if config is None:
        config = read_config()

    if not config:
        print_error("No config found")
        return None

    # Read base bootstrap template
    repo_path = Path(config['repo_path'])
    bootstrap_template_path = repo_path / 'BOOTSTRAP_PROMPT.md'

    if not bootstrap_template_path.exists():
        print_error(f"Bootstrap template not found: {bootstrap_template_path}")
        return None

    try:
        bootstrap_template = bootstrap_template_path.read_text()
    except Exception as e:
        print_error(f"Failed to read bootstrap template: {e}")
        return None

    # Read selected persona
    persona_path = get_persona_path(persona_name, config)

    if not persona_path:
        print_error(f"Persona '{persona_name}' not found")
        return None

    if not persona_path.exists():
        print_error(f"Persona file not found: {persona_path}")
        return None

    try:
        persona_content = persona_path.read_text()
    except Exception as e:
        print_error(f"Failed to read persona file: {e}")
        return None

    # Inject persona into template
    full_prompt = bootstrap_template.replace(
        '{PERSONA_CONTENT_HERE}',
        persona_content
    )

    return full_prompt


def get_subconscious_prompt_path():
    """Get path to subconscious analysis prompt"""
    config_dir = get_config_dir()
    return config_dir / 'subconscious' / 'analysis-prompt.txt'


def ensure_subconscious_prompt():
    """Ensure subconscious analysis prompt exists, create if missing"""
    prompt_path = get_subconscious_prompt_path()

    # Create directory if needed
    prompt_path.parent.mkdir(parents=True, exist_ok=True)

    # Write prompt if doesn't exist
    if not prompt_path.exists():
        print_info(f"Creating subconscious analysis prompt: {prompt_path}")
        prompt_path.write_text(ANALYSIS_PROMPT_TEMPLATE)

        # Also create README
        readme_path = prompt_path.parent / 'README.md'
        readme_content = """# Subconscious Analysis Prompt

This directory contains the system prompt used by the subconscious worker to analyze conversation recordings.

## Files

- `analysis-prompt.txt` - The prompt used for LLM analysis

## Customization

You can modify `analysis-prompt.txt` to customize how the subconscious analyzes your conversations. The prompt defines what insights are extracted (patterns, decisions, TODOs, preferences, learnings) and the output format.

## Restoring Default

If you break the prompt or want to restore the default:

```bash
samantha-llm subconscious reset-prompt
```

This will restore the original prompt template.
"""
        readme_path.write_text(readme_content)

    return prompt_path


def reset_subconscious_prompt():
    """Reset subconscious analysis prompt to default"""
    prompt_path = get_subconscious_prompt_path()

    print_info(f"Resetting subconscious analysis prompt to default")
    prompt_path.write_text(ANALYSIS_PROMPT_TEMPLATE)
    print_success(f"Prompt reset: {prompt_path}")


def install_unix():
    """Install on Unix-like systems (Linux, macOS) using symlink"""
    install_dir = get_install_dir()
    install_path = get_install_path()
    repo_dir = get_repo_dir()
    source_script = repo_dir / FILENAME

    # Create install directory
    if not install_dir.exists():
        print_info(f"Creating install directory: {install_dir}")
        install_dir.mkdir(parents=True, exist_ok=True)

    # Remove existing symlink if present
    if install_path.exists() or install_path.is_symlink():
        print_info("Removing existing symlink...")
        install_path.unlink()

    # Create symlink
    print_info(f"Creating symlink: {install_path} -> {source_script}")
    install_path.symlink_to(source_script)

    # Make source script executable
    source_script.chmod(source_script.stat().st_mode | 0o111)


def install_windows():
    """Install on Windows by copying script and creating batch wrapper"""
    install_dir = get_install_dir()
    install_path = get_install_path()
    repo_dir = get_repo_dir()
    source_script = repo_dir / FILENAME

    # Create install directory
    if not install_dir.exists():
        print_info(f"Creating install directory: {install_dir}")
        install_dir.mkdir(parents=True, exist_ok=True)

    # Copy Python script
    script_target = install_dir / FILENAME
    print_info(f"Copying script: {source_script} -> {script_target}")
    shutil.copy2(source_script, script_target)

    # Create batch wrapper
    print_info(f"Creating batch wrapper: {install_path}")
    wrapper_content = f'@echo off\npython "{script_target}" %*\n'
    install_path.write_text(wrapper_content)

    # Add to PATH
    if not check_path():
        print_info("Adding install directory to PATH...")
        if add_to_windows_path(install_dir):
            print_success("Added to PATH successfully")
            print_warning("Please restart your terminal/PowerShell for PATH changes to take effect")
        else:
            print_warning("Could not automatically add to PATH")
            print_info(f"Please manually add to your PATH: {install_dir}")


def add_to_windows_path(directory):
    """Add directory to Windows user PATH"""
    try:
        # Use setx command to modify user PATH
        # Get current PATH first
        result = subprocess.run(
            ['powershell', '-Command', '[Environment]::GetEnvironmentVariable("PATH", "User")'],
            capture_output=True,
            text=True,
            check=True
        )
        current_path = result.stdout.strip()

        # Check if already in PATH
        if str(directory).lower() in current_path.lower():
            return True

        # Add to PATH
        new_path = f'{current_path};{directory}' if current_path else str(directory)
        subprocess.run(
            ['powershell', '-Command', f'[Environment]::SetEnvironmentVariable("PATH", "{new_path}", "User")'],
            check=True,
            capture_output=True
        )
        return True
    except Exception as e:
        print_error(f"PATH update failed: {e}")
        return False


def cmd_install(args):
    """Install command"""
    print_info("Installing samantha-llm...")

    # Check for old config and migrate
    migrate_old_config()

    # Check if already installed
    if is_installed():
        print_warning("samantha-llm is already installed.")
        print_info(f"Installed at: {get_install_path()}")
        print_info(f"Config: {get_config_file()}")
        print()

        response = input("Do you want to reinstall? [y/N] ")
        if response.lower() not in ['y', 'yes']:
            print_info("Installation cancelled.")
            return 0

        print_info("Reinstalling...")

    # Create config
    if not create_config():
        print_error("Failed to create config file")
        return 1

    # Ensure subconscious prompt exists
    ensure_subconscious_prompt()

    # Platform-specific installation
    system = get_platform()
    if system == 'windows':
        install_windows()
    else:
        install_unix()

    print()
    print_success("Installation complete!")
    print()
    print_info(f"Installed to: {get_install_path()}")
    print_info(f"Config: {get_config_file()}")
    print_info(f"Repo path: {get_repo_dir()}")
    print()

    # Check PATH and warn if needed
    if not check_path():
        print_warning("The install directory is not in your PATH!")
        print()
        system = get_platform()
        if system == 'windows':
            print("Run this command in PowerShell:")
            print()
            print(f'    $env:PATH += ";{get_install_dir()}"')
            print()
            print("Or restart your terminal for persistent PATH changes.")
        else:
            print("Add the following line to your shell profile (~/.bashrc, ~/.zshrc, etc.):")
            print()
            print(f'    export PATH="${{HOME}}/.local/bin:${{PATH}}"')
            print()
            print("Then restart your shell or run:")
            print()
            shell_rc = '~/.zshrc' if Path.home() / '.zshrc' else '~/.bashrc'
            print(f"    source {shell_rc}")
        print()
    else:
        print_success("The samantha-llm command is ready to use!")

    return 0


def cmd_uninstall(args):
    """Uninstall command"""
    print_info("Uninstalling samantha-llm...")

    if not is_installed():
        print_warning("samantha-llm is not installed.")
        return 0

    install_path = get_install_path()
    install_dir = get_install_dir()
    config_dir = get_config_dir()
    system = get_platform()

    # Remove install files
    if system == 'windows':
        # Remove .bat wrapper
        if install_path.exists():
            print_info(f"Removing batch wrapper: {install_path}")
            install_path.unlink()

        # Remove copied Python script
        script_copy = install_dir / FILENAME
        if script_copy.exists():
            print_info(f"Removing script copy: {script_copy}")
            script_copy.unlink()

        # Remove directory if empty
        try:
            install_dir.rmdir()
            print_info(f"Removed install directory: {install_dir}")
        except OSError:
            pass  # Directory not empty, leave it
    else:
        # Remove symlink
        if install_path.exists() or install_path.is_symlink():
            print_info(f"Removing symlink: {install_path}")
            install_path.unlink()

    # Ask about config removal
    print()
    response = input(f"Do you want to remove the config directory ({config_dir})? [y/N] ")
    if response.lower() in ['y', 'yes']:
        print_info(f"Removing config directory: {config_dir}")
        shutil.rmtree(config_dir)
    else:
        print_info(f"Config directory preserved: {config_dir}")

    print()
    print_success("Uninstallation complete!")

    return 0


def cmd_status(args):
    """Status command"""
    print("Samantha Hartwell LLM - Installation Status")
    print("=" * 44)
    print()

    # Check installation
    if is_installed():
        print_success("Installed: Yes")
        install_path = get_install_path()
        print(f"  Location: {install_path}")

        system = get_platform()
        if system == 'windows':
            script_copy = get_install_dir() / FILENAME
            if script_copy.exists():
                print(f"  Script: {script_copy}")
        else:
            if install_path.is_symlink():
                print(f"  Target: {install_path.resolve()}")
    else:
        print_error("Installed: No")
        install_path = get_install_path()
        if install_path.exists():
            print("  Note: Install file exists but config is missing")
        config_file = get_config_file()
        if config_file.exists():
            print("  Note: Config exists but install file is missing")

    print()

    # Check config
    config_file = get_config_file()
    if config_file.exists():
        print_success("Config: Found")
        print(f"  Location: {config_file}")

        # Parse JSON config
        config = read_config()
        if config:
            if 'repo_path' in config:
                print(f"  Repo path: {config['repo_path']}")
            if 'version' in config:
                print(f"  Version: {config['version']}")
            if 'platform' in config:
                print(f"  Platform: {config['platform']}")
            if 'default_agent' in config:
                print(f"  Default agent: {config['default_agent']}")

            # Show configured agents
            if 'agents' in config and config['agents']:
                print(f"  Configured agents: {', '.join(config['agents'].keys())}")
    else:
        print_error("Config: Not found")
        print(f"  Expected: {config_file}")

    print()

    # Check PATH
    if check_path():
        print_success("PATH: Configured correctly")
        print(f"  {get_install_dir()} is in PATH")
    else:
        print_warning("PATH: Not configured")
        print(f"  {get_install_dir()} is not in PATH")

        system = get_platform()
        if system == 'windows':
            print("  Run in PowerShell: $env:PATH += \";{get_install_dir()}\"")
        else:
            print(f"  Add to shell profile: export PATH=\"${{HOME}}/.local/bin:${{PATH}}\"")

    print()

    # Check repo directory
    repo_dir = get_repo_dir()
    git_dir = repo_dir / '.git'

    if git_dir.exists():
        print_success("Repo: Valid git repository")
        print(f"  Location: {repo_dir}")

        # Show current branch if git is available
        try:
            result = subprocess.run(
                ['git', '-C', str(repo_dir), 'branch', '--show-current'],
                capture_output=True,
                text=True,
                check=True
            )
            branch = result.stdout.strip()
            if branch:
                print(f"  Branch: {branch}")
        except Exception:
            pass
    else:
        print_warning("Repo: Not a git repository")
        print(f"  Location: {repo_dir}")

    return 0


def cmd_subconscious(args):
    """Subconscious command - manage session processing and view status"""
    config = read_config()
    if not config or 'repo_path' not in config:
        print_error("samantha-llm is not installed")
        print_info("Run 'samantha-llm install' first")
        return 1

    repo_path = Path(config['repo_path'])
    subconscious_dir = repo_path / '.ai' / 'subconscious' / '.ai'

    # Handle subcommands
    if hasattr(args, 'subcommand') and args.subcommand:
        subcommand = args.subcommand
    else:
        # Default: show status
        subcommand = 'status'

    if subcommand == 'status':
        # Enhanced status display using new bootstrap_status module
        try:
            import sys
            sys.path.insert(0, str(repo_path))
            from bootstrap_status import display_processing_status

            has_active = display_processing_status(repo_path)

            if not has_active:
                print("\n✓ No active subconscious processing")

            return 0
        except ImportError:
            print_warning("Enhanced status display not available, using legacy view")
            # Fall back to legacy status display
            pass

        # Legacy status display (fallback)
        print("Subconscious Status:")
        print("=" * 50)
        print()

        # Check if worker is running
        is_running, estimated_remaining = check_worker_running(repo_path)
        if is_running:
            print_warning(f"Worker running (~{estimated_remaining}s remaining)")
        else:
            print_success("No worker running")

        # Check for guidance file
        guidance_file = subconscious_dir / 'guidance.md'
        if guidance_file.exists():
            print_info(f"Guidance file: {guidance_file}")
            print_info(f"  Last updated: {datetime.fromtimestamp(guidance_file.stat().st_mtime)}")
        else:
            print_info("No guidance file yet")

        print()
        return 0

    elif subcommand == 'retry':
        # Retry failed chunks in a session
        session_id = args.agent  # Reusing agent field for session_id

        if not session_id:
            print_error("Session ID required")
            print_info("Usage: samantha-llm subconscious retry <session_id>")
            print_info("\nTip: Use 'samantha-llm subconscious status' to see active sessions")
            return 1

        try:
            import sys
            sys.path.insert(0, str(repo_path))
            from chunk_retry import retry_session

            print()
            retry_session(session_id, repo_path)
            return 0

        except ImportError as e:
            print_error(f"Chunk retry module not available: {e}")
            print_info("This feature requires the latest subconscious implementation")
            return 1
        except Exception as e:
            print_error(f"Retry failed: {e}")
            return 1

    elif subcommand == 'reprocess':
        # Reprocess failed sessions (those with no LLM analysis)
        session_id = args.agent if hasattr(args, 'agent') and args.agent else None

        try:
            import sys
            import json
            sys.path.insert(0, str(repo_path))
            from session_workspace import get_session_workspaces

            sessions_dir = repo_path / '.ai' / 'subconscious' / '.ai' / 'sessions'
            processed_dir = repo_path / '.ai' / 'subconscious' / '.ai' / 'processed'

            if not sessions_dir.exists():
                print_error("No sessions directory found")
                return 1

            # Find failed sessions (patterns_count: 0, decisions_count: 0)
            failed_sessions = []

            if session_id:
                # Specific session requested
                target_sessions = [session_id]
            else:
                # Find all sessions
                target_sessions = [d.name for d in sessions_dir.iterdir() if d.is_dir()]

            for sid in target_sessions:
                status_file = sessions_dir / sid / 'status.json'
                if status_file.exists():
                    with open(status_file) as f:
                        status = json.load(f)

                    # Check if LLM analysis failed (0 patterns and 0 decisions)
                    if status.get('patterns_count', 0) == 0 and status.get('decisions_count', 0) == 0:
                        failed_sessions.append(sid)

            if not failed_sessions:
                if session_id:
                    print_info(f"Session {session_id} does not need reprocessing")
                else:
                    print_success("No failed sessions found - all sessions processed successfully!")
                return 0

            print(f"\nFound {len(failed_sessions)} session(s) to reprocess:")
            for sid in failed_sessions:
                print(f"  • {sid}")
            print()

            # Confirm if processing multiple sessions
            if len(failed_sessions) > 1 and not session_id:
                response = input(f"Reprocess {len(failed_sessions)} sessions? [y/N] ")
                if response.lower() not in ['y', 'yes']:
                    print_info("Cancelled.")
                    return 0

            # Reprocess each failed session
            success_count = 0
            for i, sid in enumerate(failed_sessions, 1):
                print(f"\n[{i}/{len(failed_sessions)}] Reprocessing session {sid}...")

                # Find transcript in processed directory
                transcript_files = list(processed_dir.glob(f'transcript_{sid}_*.jsonl'))
                if not transcript_files:
                    print_warning(f"  No transcript found for session {sid}")
                    continue

                transcript_file = transcript_files[0]

                # Invoke worker
                try:
                    worker_script = repo_path / 'subconscious_worker.py'
                    result = subprocess.run(
                        [sys.executable, str(worker_script), str(transcript_file), str(repo_path)],
                        capture_output=True,
                        text=True,
                        timeout=300  # 5 minute timeout per session
                    )

                    if result.returncode == 0:
                        # Check if it succeeded
                        with open(status_file) as f:
                            new_status = json.load(f)

                        patterns = new_status.get('patterns_count', 0)
                        decisions = new_status.get('decisions_count', 0)

                        if patterns > 0 or decisions > 0:
                            print_success(f"  ✓ Success: {patterns} patterns, {decisions} decisions")
                            success_count += 1
                        else:
                            print_warning(f"  Analysis completed but found no patterns/decisions")
                    else:
                        print_error(f"  Worker failed with exit code {result.returncode}")
                        if result.stderr:
                            print_info(f"  Error: {result.stderr[:200]}")

                except subprocess.TimeoutExpired:
                    print_error(f"  Timeout after 5 minutes")
                except Exception as e:
                    print_error(f"  Failed: {e}")

            print()
            print("=" * 60)
            print(f"Reprocessing complete: {success_count}/{len(failed_sessions)} succeeded")

            if success_count > 0:
                print_info(f"\nRun 'samantha-llm subconscious merge' to integrate memories into cerebrum")

            return 0

        except ImportError as e:
            print_error(f"Required module not available: {e}")
            return 1
        except Exception as e:
            print_error(f"Reprocess failed: {e}")
            import traceback
            traceback.print_exc()
            return 1

    elif subcommand == 'merge':
        # Merge completed sessions
        try:
            import sys
            sys.path.insert(0, str(repo_path))
            from merge_sessions import merge_completed_sessions

            print()
            merge_completed_sessions(repo_path, dry_run=False)
            return 0

        except ImportError as e:
            print_error(f"Merge module not available: {e}")
            print_info("This feature requires the latest subconscious implementation")
            return 1
        except Exception as e:
            print_error(f"Merge failed: {e}")
            return 1

    elif subcommand == 'list':
        # List all sessions (active and archived)
        try:
            import sys
            sys.path.insert(0, str(repo_path))
            from session_workspace import get_session_workspaces

            workspaces = get_session_workspaces(repo_path)

            if not workspaces:
                print_info("No active sessions found")
                return 0

            print(f"\nActive Session Workspaces ({len(workspaces)}):")
            print("=" * 60)

            for ws in sorted(workspaces, key=lambda w: w.session_id, reverse=True):
                status = ws.get_status()
                status_symbol = {
                    'processing': '⏳',
                    'complete': '✅',
                    'failed': '❌'
                }.get(status.get('status'), '?')

                print(f"\n{status_symbol} Session: {ws.session_id}")
                print(f"   Status: {status.get('status', 'unknown')}")
                if 'created_at' in status:
                    print(f"   Created: {status['created_at']}")
                if status.get('status') == 'complete' and 'completed_at' in status:
                    print(f"   Completed: {status['completed_at']}")

            print()
            return 0

        except ImportError:
            print_error("Session workspace module not available")
            return 1

    elif subcommand == 'status-old':
        # Legacy status display (kept for compatibility)
        print("Subconscious Status (Legacy):")
        print("=" * 50)
        print()

        # Check if worker is running
        is_running, estimated_remaining = check_worker_running(repo_path)
        if is_running:
            print_warning(f"Worker running (~{estimated_remaining}s remaining)")
        else:
            print_success("No worker running")

        # Check for guidance file
        guidance_file = subconscious_dir / 'guidance.md'
        if guidance_file.exists():
            print_info(f"Guidance file: {guidance_file}")
            print_info(f"  Last updated: {datetime.fromtimestamp(guidance_file.stat().st_mtime)}")
        else:
            print_info("No guidance file yet")

        print()
        return 0

    elif subcommand == 'guidance':
        # Show guidance file
        guidance_file = subconscious_dir / 'guidance.md'
        if not guidance_file.exists():
            print_warning("No guidance file found")
            print_info("Guidance will be generated after your first session")
            return 0

        print("Subconscious Guidance:")
        print("=" * 50)
        print()
        with open(guidance_file) as f:
            print(f.read())
        return 0

    elif subcommand == 'wait':
        # Wait for worker to finish
        is_running, _ = check_worker_running(repo_path)
        if not is_running:
            print_info("No worker running")
            return 0

        print_info("Waiting for worker to finish...")
        wait_for_worker(repo_path, timeout=60)
        print_success("Worker finished")
        return 0

    elif subcommand == 'reset-prompt':
        # Reset analysis prompt to default
        print_warning("This will reset your subconscious analysis prompt to the default.")
        print_info("Any customizations will be lost.")
        print()

        response = input("Continue? [y/N] ")
        if response.lower() not in ['y', 'yes']:
            print_info("Cancelled.")
            return 0

        reset_subconscious_prompt()
        return 0

    else:
        print_error(f"Unknown subcommand: {subcommand}")
        print()
        print_info("Available subcommands:")
        print_info("  status         - Show active session processing status")
        print_info("  retry <id>     - Retry failed chunks in a session")
        print_info("  reprocess [id] - Reprocess failed sessions (no LLM analysis)")
        print_info("  merge          - Merge completed sessions into cerebrum")
        print_info("  list           - List all active session workspaces")
        print_info("  guidance       - Show conversation analysis guidance")
        print_info("  wait           - Wait for worker to finish processing")
        print_info("  reset-prompt   - Reset analysis prompt to default")
        return 1


def cmd_help(args):
    """Help command"""
    print("""samantha-llm - Samantha Hartwell LLM Management Tool

Usage:
    samantha-llm install           Install samantha-llm and configure environment
    samantha-llm uninstall         Remove samantha-llm installation
    samantha-llm setup             Configure an agent for LLM sessions
    samantha-llm setup --default AGENT  Set default agent
    samantha-llm agents            List configured agents
    samantha-llm start [AGENT]     Start a session (uses default agent/persona if not specified)
    samantha-llm start --persona NAME   Start a session with specific persona
    samantha-llm personas          List registered personas
    samantha-llm personas --set-default NAME  Set default persona
    samantha-llm register-persona NAME FILE   Register a custom persona
    samantha-llm register-persona NAME FILE --description DESC  Register with description
    samantha-llm unregister-persona NAME      Remove a custom persona
    samantha-llm link              Link current directory to samantha-llm (create .ai-cerebrum symlink)
    samantha-llm unlink            Unlink current directory from samantha-llm (remove .ai-cerebrum symlink)
    samantha-llm qmd install       Install qmd (memory search engine) and dependencies
    samantha-llm qmd status        Show qmd installation status
    samantha-llm qmd check         Quick check if qmd is available
    samantha-llm memories index    Index cerebrum files for semantic search
    samantha-llm memories search   Search memories with semantic/keyword search
    samantha-llm subconscious status         Show active session processing status
    samantha-llm subconscious retry <id>     Retry failed chunks in a session
    samantha-llm subconscious reprocess [id] Reprocess failed sessions (no LLM analysis)
    samantha-llm subconscious merge          Merge completed sessions into cerebrum
    samantha-llm subconscious list           List all active session workspaces
    samantha-llm subconscious guidance       Show conversation analysis guidance
    samantha-llm subconscious wait           Wait for worker to finish processing
    samantha-llm subconscious reset-prompt   Reset analysis prompt to default
    samantha-llm status            Show installation status and configuration
    samantha-llm version           Show version information
    samantha-llm help              Show this help message

Description:
    This tool manages the installation and configuration of the Samantha
    Hartwell LLM memory system. After installation, the samantha-llm command
    will be available system-wide.

    Use 'setup' to configure an agent (Claude Code, Abacus.ai, GitHub Copilot,
    or custom). Use 'start' to begin a Samantha session in the current
    workspace - it will automatically link the workspace, run the agent with
    the bootstrap prompt, and clean up when the session ends.

    Use 'link' to manually activate samantha-llm in a project directory, and
    'unlink' to deactivate it. This creates/removes a .ai-cerebrum symlink that
    provides access to the samantha-llm repository and memory system.

    Supports Linux, macOS, and Windows.

Examples:
    # Install samantha-llm system-wide
    ./samantha-llm install

    # Configure an agent
    samantha-llm setup

    # Start a Samantha session (uses default agent)
    cd /path/to/project
    samantha-llm start

    # Start a session with a specific agent
    samantha-llm start claude

    # Link a project directory to samantha-llm (manual)
    cd /path/to/project
    samantha-llm link

    # Check installation status
    samantha-llm status

    # List configured agents
    samantha-llm agents

    # Change default agent
    samantha-llm setup --default claude

    # Register a custom persona
    samantha-llm register-persona tax-accountant ./my-persona.md

    # List personas
    samantha-llm personas

    # Start session with specific persona
    samantha-llm start --persona tax-accountant

    # Set default persona
    samantha-llm personas --set-default tax-accountant

    # Unlink a project directory
    cd /path/to/project
    samantha-llm unlink

    # Uninstall samantha-llm
    samantha-llm uninstall

    # Check subconscious processing status
    samantha-llm subconscious status

    # Retry failed chunks after laptop sleep
    samantha-llm subconscious retry 20260205_120000

    # Merge completed sessions
    samantha-llm subconscious merge

Platform-Specific Notes:
    Linux/macOS: Installs to ~/.local/bin using symlink
    Windows:     Installs to %LOCALAPPDATA%\\Programs\\samantha-llm using batch wrapper
""")
    return 0


def cmd_version(args):
    """Version command"""
    print(f"samantha-llm version {VERSION}")
    print(f"Platform: {get_platform()}")
    print(f"Python: {sys.version.split()[0]}")
    return 0


def cmd_link(args):
    """Link command - create .ai-cerebrum symlink in current directory"""
    cwd = Path.cwd()
    symlink_path = cwd / '.ai-cerebrum'

    # Get repo path from config
    config = read_config()
    if not config:
        print_error("samantha-llm is not installed")
        print_info("Run 'samantha-llm install' first")
        return 1

    if 'repo_path' not in config:
        print_error("Config file is missing repo_path")
        return 1

    repo_path = Path(config['repo_path'])

    # Check if repo path exists
    if not repo_path.exists():
        print_error(f"Repository not found: {repo_path}")
        print_info("Please reinstall samantha-llm")
        return 1

    # Check if symlink already exists
    if symlink_path.exists() or symlink_path.is_symlink():
        # Check if it points to the correct location
        if symlink_path.is_symlink():
            current_target = symlink_path.resolve()
            if current_target == repo_path:
                print_success(f"Already linked to samantha-llm")
                print_info(f"  Current directory: {cwd}")
                print_info(f"  Linked to: {repo_path}")
                return 0
            else:
                print_warning(f"Symlink exists but points to wrong location")
                print_info(f"  Current target: {current_target}")
                print_info(f"  Expected target: {repo_path}")
                print()
                response = input("Do you want to relink to the correct location? [y/N] ")
                if response.lower() not in ['y', 'yes']:
                    print_info("Link cancelled")
                    return 0
                print_info("Removing old symlink...")
                symlink_path.unlink()
        else:
            print_error(f"A file or directory named '.ai-cerebrum' already exists")
            print_info(f"  Location: {symlink_path}")
            print_info("Please remove it manually before linking")
            return 1

    # Create symlink
    try:
        print_info(f"Creating symlink: {symlink_path} -> {repo_path}")
        symlink_path.symlink_to(repo_path)

        # Track this workspace as manually linked
        if 'workspaces' not in config:
            config['workspaces'] = {}
        config['workspaces'][str(cwd)] = {
            'linked_at': datetime.now().isoformat(),
            'manual': True
        }
        write_config(config)

        print()
        print_success("Successfully linked to samantha-llm!")
        print()
        print_info(f"  Current directory: {cwd}")
        print_info(f"  Linked to: {repo_path}")
        print()
        print_info("You can now access samantha-llm via .ai-cerebrum/")
        print_info("Example: cat .ai-cerebrum/BOOTSTRAP_PROMPT.md")
        return 0
    except Exception as e:
        print_error(f"Failed to create symlink: {e}")
        return 1


def cmd_unlink(args):
    """Unlink command - remove .ai-cerebrum symlink from current directory"""
    cwd = Path.cwd()
    symlink_path = cwd / '.ai-cerebrum'

    # Check if symlink exists
    if not symlink_path.exists() and not symlink_path.is_symlink():
        print_warning("Not linked - no .ai-cerebrum symlink found")
        print_info(f"  Current directory: {cwd}")
        return 0

    # Check if it's actually a symlink
    if not symlink_path.is_symlink():
        print_error(f"'.ai-cerebrum' exists but is not a symlink")
        print_info(f"  Location: {symlink_path}")
        print_info("Please remove it manually")
        return 1

    # Show what we're unlinking
    target = symlink_path.resolve()
    print_info(f"Unlinking from samantha-llm...")
    print_info(f"  Current directory: {cwd}")
    print_info(f"  Currently linked to: {target}")
    print()

    # Ask for confirmation
    response = input("Remove .ai-cerebrum symlink? [y/N] ")
    if response.lower() not in ['y', 'yes']:
        print_info("Unlink cancelled")
        return 0

    # Remove symlink
    try:
        symlink_path.unlink()

        # Remove from workspace tracking
        config = read_config()
        if config and 'workspaces' in config and str(cwd) in config['workspaces']:
            del config['workspaces'][str(cwd)]
            write_config(config)

        print()
        print_success("Successfully unlinked!")
        print_info(f"  Removed: {symlink_path}")
        return 0
    except Exception as e:
        print_error(f"Failed to remove symlink: {e}")
        return 1


def cmd_setup(args):
    """Setup command - configure agents"""
    print_info("Samantha LLM Agent Setup")
    print()

    # Check if installed
    config = read_config()
    if not config:
        print_error("samantha-llm is not installed")
        print_info("Run 'samantha-llm install' first")
        return 1

    # Check if --default flag is used
    if hasattr(args, 'default_agent') and args.default_agent:
        # Just change default agent
        agent_name = args.default_agent
        if 'agents' not in config or agent_name not in config['agents']:
            print_error(f"Agent '{agent_name}' is not configured")
            print_info("Available agents: " + ', '.join(config.get('agents', {}).keys()))
            return 1

        config['default_agent'] = agent_name
        if write_config(config):
            print_success(f"Default agent set to: {agent_name}")
            return 0
        else:
            return 1

    # Interactive setup
    print("Select your preferred Agentic LLM tool:")
    print()
    print("1) Claude Code")
    print("2) Abacus.ai")
    print("3) GitHub Copilot")
    print("4) Other (manual setup)")
    print()

    choice = input("Enter your choice [1-4]: ").strip()

    agent_config = None
    agent_name = None

    if choice == '1':
        agent_name = 'claude'
        agent_config = {
            'command': 'claude',
            'bootstrap_file': 'BOOTSTRAP_PROMPT.md'
        }
        print_info("Configuring Claude Code...")
    elif choice == '2':
        agent_name = 'abacus'
        agent_config = {
            'command': 'npx abacusai',
            'bootstrap_file': 'BOOTSTRAP_PROMPT.md'
        }
        print_info("Configuring Abacus.ai...")
    elif choice == '3':
        agent_name = 'copilot'
        agent_config = {
            'command': 'npx copilot -i',
            'bootstrap_file': 'BOOTSTRAP_PROMPT.md'
        }
        print_info("Configuring GitHub Copilot...")
    elif choice == '4':
        print()
        print_info("Manual agent setup")
        agent_name = input("Enter agent name (e.g., 'myagent'): ").strip()
        if not agent_name:
            print_error("Agent name cannot be empty")
            return 1

        command = input("Enter command to run agent (e.g., 'npx myagent'): ").strip()
        if not command:
            print_error("Command cannot be empty")
            return 1

        bootstrap_file = input("Enter bootstrap file name [BOOTSTRAP_PROMPT.md]: ").strip()
        if not bootstrap_file:
            bootstrap_file = 'BOOTSTRAP_PROMPT.md'

        agent_config = {
            'command': command,
            'bootstrap_file': bootstrap_file
        }
        print_info(f"Configuring {agent_name}...")
    else:
        print_error("Invalid choice")
        return 1

    # Add agent to config
    if 'agents' not in config:
        config['agents'] = {}

    config['agents'][agent_name] = agent_config

    # Set as default if it's the first agent or user confirms
    if 'default_agent' not in config or not config.get('agents'):
        config['default_agent'] = agent_name
        print_info(f"Setting {agent_name} as default agent")
    else:
        print()
        response = input(f"Set {agent_name} as default agent? [Y/n] ").strip().lower()
        if response in ['', 'y', 'yes']:
            config['default_agent'] = agent_name

    # Save config
    if write_config(config):
        print()
        print_success(f"Agent '{agent_name}' configured successfully!")
        print_info(f"  Command: {agent_config['command']}")
        print_info(f"  Bootstrap: {agent_config['bootstrap_file']}")
        if config.get('default_agent') == agent_name:
            print_info(f"  Default: Yes")
        print()
        print_info("You can now use 'samantha-llm start' to begin a session")
        return 0
    else:
        return 1


def cmd_agents(args):
    """Agents command - list configured agents"""
    config = read_config()
    if not config:
        print_error("samantha-llm is not installed")
        print_info("Run 'samantha-llm install' first")
        return 1

    agents = config.get('agents', {})
    default_agent = config.get('default_agent')

    if not agents:
        print_warning("No agents configured")
        print_info("Run 'samantha-llm setup' to configure an agent")
        return 0

    print("Configured Agents:")
    print("=" * 50)
    print()

    for name, agent_config in agents.items():
        is_default = " (default)" if name == default_agent else ""
        print(f"{name}{is_default}")
        print(f"  Command: {agent_config.get('command', 'N/A')}")
        print(f"  Bootstrap: {agent_config.get('bootstrap_file', 'N/A')}")
        print()

    return 0


# ============================================================================
# Subconscious Worker Functions
# ============================================================================

def get_lockfile_path(repo_path: Path) -> Path:
    """Get path to subconscious worker lock file."""
    return repo_path / '.ai' / 'subconscious' / '.ai' / '.processing.lock'


def check_worker_running(repo_path: Path) -> tuple:
    """
    Check if subconscious worker is running.

    Returns:
        (is_running, estimated_seconds_remaining)
    """
    lockfile = get_lockfile_path(repo_path)

    if not lockfile.exists():
        return (False, 0)

    # Estimate time remaining based on lock file age
    elapsed = time.time() - lockfile.stat().st_mtime
    estimated_remaining = max(0, 30 - elapsed)  # Assume 30 second processing time

    return (True, int(estimated_remaining))


def wait_for_worker(repo_path: Path, timeout: int = 60):
    """
    Wait for subconscious worker to finish.

    Args:
        repo_path: Path to repository
        timeout: Maximum seconds to wait
    """
    lockfile = get_lockfile_path(repo_path)

    start = time.time()
    while lockfile.exists():
        if time.time() - start > timeout:
            print_warning(f"Timeout waiting for memory processing ({timeout}s)")
            # Remove stale lock
            try:
                lockfile.unlink()
            except:
                pass
            break
        time.sleep(0.5)


def prompt_for_worker_wait(repo_path: Path) -> bool:
    """
    Prompt user whether to wait for running worker.

    Returns:
        True if user wants to wait, False otherwise
    """
    is_running, estimated_remaining = check_worker_running(repo_path)

    if not is_running:
        return False

    print()
    print_warning("Memory processing from previous session is still running.")
    print()
    print("Would you like to:")
    print(f"  [1] Wait for processing to complete (~{estimated_remaining}s remaining)")
    print("  [2] Start now (new memories will be available next session)")
    print()

    choice = input("Choice [1/2]: ").strip()

    if choice == '1':
        print()
        print_info("⏳ Waiting for memory processing...")
        wait_for_worker(repo_path, timeout=60)
        print_success("✓ Memories updated")
        print()
        return True
    else:
        print()
        print_info("→ Starting session (processing will continue in background)")
        print()
        return False


def spawn_subconscious_worker(transcript_file: Path, cerebrum_path: Path):
    """
    Spawn background worker to process transcript.

    Args:
        transcript_file: Path to transcript file
        cerebrum_path: Path to cerebrum root
    """
    worker_script = cerebrum_path / 'subconscious_worker.py'

    if not worker_script.exists():
        # Worker script not found, skip processing
        return

    # Prepare worker command
    cmd = [
        sys.executable,  # Python interpreter
        str(worker_script),
        str(transcript_file),
        str(cerebrum_path)
    ]

    # Platform-specific spawning
    try:
        if sys.platform == 'win32':
            # Windows: Use DETACHED_PROCESS flag
            DETACHED_PROCESS = 0x00000008
            subprocess.Popen(
                cmd,
                creationflags=DETACHED_PROCESS,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                stdin=subprocess.DEVNULL,
                close_fds=True
            )
        else:
            # Unix (Linux/Mac): Use start_new_session
            subprocess.Popen(
                cmd,
                start_new_session=True,  # Detach from parent
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                stdin=subprocess.DEVNULL,
                close_fds=True
            )
    except Exception as e:
        # Silently fail - don't interrupt user experience
        pass


# ============================================================================
# Terminal Recording
# ============================================================================

def run_agent_with_recording(
    agent_command: list,
    cwd: Path,
    recording_file: Path
) -> int:
    """
    Run agent command with terminal recording.

    Uses platform-specific terminal recording to capture all I/O.

    Args:
        agent_command: Command to execute (as list)
        cwd: Working directory
        recording_file: Path to save terminal recording

    Returns:
        Exit code from agent
    """
    system = get_platform()

    if system == 'windows':
        # Windows: Use PowerShell Start-Transcript
        # Note: This captures PowerShell output, not raw terminal
        ps_command = f"""
Start-Transcript -Path '{recording_file}' -Force
try {{
    & {' '.join(f'"{part}"' if ' ' in part else part for part in agent_command)}
    exit $LASTEXITCODE
}} finally {{
    Stop-Transcript
}}
"""
        cmd = ['powershell', '-NoProfile', '-Command', ps_command]

        try:
            result = subprocess.run(
                cmd,
                stdin=sys.stdin,
                stdout=sys.stdout,
                stderr=sys.stderr,
                cwd=str(cwd)
            )
            return result.returncode
        except Exception as e:
            print_error(f"Failed to execute agent with recording: {e}")
            return 1

    else:
        # Unix/Mac: Use 'script' command
        # -q: Quiet (no start/done messages)
        # -c: Command to run
        # Note: -f/--flush flag varies by version, so we omit it

        # Build command string for script
        import shlex
        cmd_string = ' '.join(shlex.quote(part) for part in agent_command)

        cmd = [
            'script',
            '-q',           # Quiet mode (widely supported)
            '-c',
            cmd_string,
            str(recording_file)
        ]

        try:
            result = subprocess.run(
                cmd,
                stdin=sys.stdin,
                stdout=sys.stdout,
                stderr=sys.stderr,
                cwd=str(cwd)
            )
            return result.returncode
        except FileNotFoundError:
            print_error("'script' command not found")
            print_info("Terminal recording requires 'script' (usually in util-linux package)")
            print_info("Falling back to execution without recording...")

            # Fallback: run without recording
            try:
                result = subprocess.run(
                    agent_command,
                    stdin=sys.stdin,
                    stdout=sys.stdout,
                    stderr=sys.stderr,
                    cwd=str(cwd)
                )
                return result.returncode
            except Exception as e:
                print_error(f"Failed to execute agent: {e}")
                return 1
        except Exception as e:
            print_error(f"Failed to execute agent with recording: {e}")
            return 1


# ============================================================================
# Session Commands
# ============================================================================

def cmd_start(args):
    """Start command - begin a Samantha Hartwell LLM session in current workspace"""
    cwd = Path.cwd()
    symlink_path = cwd / '.ai-cerebrum'

    # Get config
    config = read_config()
    if not config:
        print_error("samantha-llm is not installed")
        print_info("Run 'samantha-llm install' first")
        return 1

    # Check if repo path exists
    if 'repo_path' not in config:
        print_error("Config file is missing repo_path")
        return 1

    repo_path = Path(config['repo_path'])
    if not repo_path.exists():
        print_error(f"Repository not found: {repo_path}")
        print_info("Please reinstall samantha-llm")
        return 1

    # Determine which agent to use
    # NOTE: Due to positional arg parsing, agent name might be in subcommand position
    agent_name = args.agent or args.subcommand or config.get('default_agent')

    if not agent_name:
        print_error("No agent configured")
        print_info("Run 'samantha-llm setup' to configure an agent")
        return 1

    agents = config.get('agents', {})
    if agent_name not in agents:
        print_error(f"Agent '{agent_name}' not found")
        print_info("Available agents:")
        for name in agents.keys():
            print_info(f"  - {name}")
        print_info("Run 'samantha-llm agents' to see all configured agents")
        return 1

    agent_config = agents[agent_name]
    agent_command = agent_config.get('command')
    bootstrap_file = agent_config.get('bootstrap_file', 'BOOTSTRAP_PROMPT.md')

    if not agent_command:
        print_error(f"Agent '{agent_name}' has no command configured")
        return 1

    # Check if workspace is already linked
    workspaces = config.get('workspaces', {})
    is_manual_link = str(cwd) in workspaces and workspaces[str(cwd)].get('manual', False)
    auto_linked = False

    # Auto-link if needed
    if not symlink_path.exists() and not symlink_path.is_symlink():
        print_info(f"Auto-linking workspace to samantha-llm...")
        try:
            symlink_path.symlink_to(repo_path)
            auto_linked = True

            # Track as auto-linked workspace
            if 'workspaces' not in config:
                config['workspaces'] = {}
            config['workspaces'][str(cwd)] = {
                'linked_at': datetime.now().isoformat(),
                'manual': False
            }
            write_config(config)

            print_success("Workspace linked")
        except Exception as e:
            print_error(f"Failed to create symlink: {e}")
            return 1
    elif symlink_path.is_symlink():
        # Verify it points to correct location
        current_target = symlink_path.resolve()
        if current_target != repo_path:
            print_error(f"Symlink exists but points to wrong location")
            print_info(f"  Current target: {current_target}")
            print_info(f"  Expected target: {repo_path}")
            print_info("Run 'samantha-llm link' to fix the symlink")
            return 1
    elif symlink_path.exists():
        print_error(f"A file or directory named '.ai-cerebrum' already exists")
        print_info(f"  Location: {symlink_path}")
        print_info("Please remove it manually before starting a session")
        return 1

    # Check for running subconscious worker and prompt user
    prompt_for_worker_wait(repo_path)

    # Ensure config is migrated to latest version (for persona support)
    config = ensure_config_migrated()

    # Determine which persona to use
    persona_name = args.persona if hasattr(args, 'persona') and args.persona else config.get('default_persona', 'samantha-hartwell')

    # Generate bootstrap prompt with selected persona
    bootstrap_content = generate_bootstrap_prompt(persona_name, config)
    if not bootstrap_content:
        print_error(f"Failed to generate bootstrap prompt for persona: {persona_name}")
        return 1

    try:
        pass  # bootstrap_content already generated above
    except Exception as e:
        print_error(f"Failed to read bootstrap file: {e}")
        return 1

    # Set up transcript capture
    try:
        # Import transcript capture module
        transcript_module_path = repo_path / 'transcript_capture.py'
        if transcript_module_path.exists():
            import importlib.util
            spec = importlib.util.spec_from_file_location("transcript_capture", transcript_module_path)
            transcript_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(transcript_module)

            # Create transcript capture
            transcript = transcript_module.TranscriptCapture(agent_name, cwd)
            transcript.start_session()
            has_transcript = True
        else:
            has_transcript = False
            transcript = None
    except Exception as e:
        # Transcript capture failed, continue without it
        has_transcript = False
        transcript = None

    # Prepare agent command
    # Parse command string (handle spaces in command)
    import shlex
    cmd_parts = shlex.split(agent_command)
    cmd_parts.append(bootstrap_content)

    # Create terminal recording file
    import tempfile
    recording_file = None
    if has_transcript:
        # Store recording next to transcript for processing
        temp_dir = tempfile.gettempdir()
        session_id = transcript.session_id if transcript else datetime.now().strftime("%Y%m%d_%H%M%S")
        recording_file = Path(temp_dir) / f'terminal_{session_id}.txt'

    print()
    print_info(f"Starting Samantha Hartwell session with agent '{agent_name}'")
    print_info(f"  Workspace: {cwd}")
    print_info(f"  Command: {agent_command}")
    if has_transcript:
        print_info(f"  Transcript: Capturing conversation (subconscious enabled)")
    print()

    # Record session start time
    session_start_time = time.time()

    # Execute agent command with terminal recording
    if recording_file:
        exit_code = run_agent_with_recording(cmd_parts, cwd, recording_file)
    else:
        # Fallback: run without recording
        try:
            result = subprocess.run(
                cmd_parts,
                stdin=sys.stdin,
                stdout=sys.stdout,
                stderr=sys.stderr,
                cwd=str(cwd)
            )
            exit_code = result.returncode
        except FileNotFoundError:
            print_error(f"Agent command not found: {agent_command}")
            print_info("Make sure the agent is installed and in your PATH")
            exit_code = 127
        except Exception as e:
            print_error(f"Failed to execute agent: {e}")
            exit_code = 1

    # Record session end and spawn worker
    if has_transcript and transcript:
        try:
            session_duration = time.time() - session_start_time
            transcript.end_session(session_duration)
            transcript_file = transcript.close()

            # Save transcript to cerebrum
            saved_transcript = transcript_module.save_transcript_to_cerebrum(
                transcript_file,
                repo_path
            )

            # Save terminal recording to cerebrum if it exists
            if recording_file and recording_file.exists():
                # Create recordings directory
                recordings_dir = repo_path / '.ai' / 'subconscious' / '.ai' / 'recordings'
                recordings_dir.mkdir(parents=True, exist_ok=True)

                # Move recording to cerebrum
                target_recording = recordings_dir / recording_file.name
                shutil.move(str(recording_file), str(target_recording))

                print()
                print_info("📝 Session transcript saved")
                print_info("📼 Terminal recording saved")
            else:
                print()
                print_info("📝 Session transcript saved")

            # Spawn subconscious worker
            spawn_subconscious_worker(saved_transcript, repo_path)
            print_info("🧠 Memory processing started in background")

        except Exception as e:
            # Failed to save transcript or spawn worker, continue anyway
            pass

    # Cleanup auto-linked workspace
    if auto_linked and not is_manual_link:
        print()
        print_info("Cleaning up auto-linked workspace...")
        try:
            if symlink_path.is_symlink():
                symlink_path.unlink()
            # Remove from config
            if str(cwd) in config.get('workspaces', {}):
                del config['workspaces'][str(cwd)]
                write_config(config)
            print_success("Workspace unlinked")
        except Exception as e:
            print_warning(f"Failed to cleanup workspace: {e}")
            print_info("You may need to run 'samantha-llm unlink' manually")

    return exit_code


# ============================================================================
# QMD Commands
# ============================================================================

def is_command_available(command):
    """Check if a command is available on PATH"""
    return shutil.which(command) is not None


def is_bun_installed():
    """Check if Bun runtime is installed"""
    return is_command_available('bun')


def get_qmd_local_dir():
    """Get local qmd installation directory"""
    return Path.home() / '.local' / 'share' / 'samantha-llm' / 'qmd'


def get_qmd_bin_path():
    """Get path to qmd binary (global or local)"""
    # Check global install first
    global_bin = shutil.which('qmd')
    if global_bin:
        return global_bin

    # Check bun global install (~/node_modules/qmd/qmd)
    bun_global = Path.home() / 'node_modules' / 'qmd' / 'qmd'
    if bun_global.exists() and os.access(bun_global, os.X_OK):
        return str(bun_global)

    # Check local install
    local_bin = get_qmd_local_dir() / 'node_modules' / 'qmd' / 'qmd'
    if local_bin.exists() and os.access(local_bin, os.X_OK):
        return str(local_bin)

    # Also check .bin directories
    local_bin_dir = get_qmd_local_dir() / 'node_modules' / '.bin' / 'qmd'
    if local_bin_dir.exists() and os.access(local_bin_dir, os.X_OK):
        return str(local_bin_dir)

    return None


def is_qmd_installed():
    """Check if qmd is installed (global or local)"""
    return get_qmd_bin_path() is not None


def get_qmd_models_dir():
    """Get qmd models directory"""
    return Path.home() / '.cache' / 'qmd' / 'models'


def get_qmd_config_file():
    """Get qmd config file path"""
    return get_config_dir() / 'qmd-config.json'


def install_bun():
    """Install Bun runtime"""
    print_info("Installing Bun runtime...")

    system = get_platform()

    if system == 'windows':
        print_error("Windows is not yet supported for automatic Bun installation")
        print_info("Please install Bun manually: https://bun.sh/docs/installation")
        print_info("Or use WSL (Windows Subsystem for Linux)")
        return False

    # Use official Bun installer for Linux and macOS
    install_cmd = "curl -fsSL https://bun.sh/install | bash"

    print_info("Running: curl -fsSL https://bun.sh/install | bash")
    print_warning("This will download and install Bun to ~/.bun")

    try:
        result = subprocess.run(
            install_cmd,
            shell=True,
            capture_output=True,
            text=True
        )

        if result.returncode != 0:
            print_error(f"Bun installation failed: {result.stderr}")
            return False

        print_success("Bun installed successfully")

        # Check if Bun is now in PATH
        if not is_bun_installed():
            print_warning("Bun installed but not found in PATH")
            print_info("You may need to restart your shell or run:")
            print_info("  source ~/.bashrc  (or ~/.zshrc)")
            bun_path = Path.home() / '.bun' / 'bin'
            print_info(f"  Or add to PATH: export PATH=\"{bun_path}:$PATH\"")
            return False

        return True

    except Exception as e:
        print_error(f"Failed to install Bun: {e}")
        return False


def install_qmd():
    """Install qmd via Bun (try global first, fall back to local)"""
    print_info("Installing qmd from github:tobi/qmd...")

    if not is_bun_installed():
        print_error("Bun is not installed. Install Bun first with: samantha-llm qmd install-bun")
        return False

    install_type = None

    # Try global install first
    print_info("Attempting global install...")
    try:
        result = subprocess.run(
            ['bun', 'install', '-g', 'github:tobi/qmd'],
            capture_output=True,
            text=True
        )

        if result.returncode == 0:
            print_success("Global install successful")
            install_type = "global"
        else:
            print_warning(f"Global install failed: {result.stderr.strip()}")
            print_info("Falling back to local install...")

    except Exception as e:
        print_warning(f"Global install failed: {e}")
        print_info("Falling back to local install...")

    # Try local install if global failed
    if install_type is None:
        local_dir = get_qmd_local_dir()
        local_dir.mkdir(parents=True, exist_ok=True)

        try:
            result = subprocess.run(
                ['bun', 'install', 'github:tobi/qmd'],
                cwd=str(local_dir),
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                print_error(f"Local install failed: {result.stderr}")
                return False

            print_success(f"Local install successful: {local_dir}")
            install_type = "local"

        except Exception as e:
            print_error(f"Failed to install qmd: {e}")
            return False

    # Check if qmd is now available
    qmd_bin = get_qmd_bin_path()
    if not qmd_bin:
        print_error("qmd installed but binary not found")
        print_info("Try running: samantha-llm qmd status")
        return False

    print_success(f"qmd binary: {qmd_bin}")

    # Create config file
    config_file = get_qmd_config_file()
    config_dir = get_config_dir()
    config_dir.mkdir(parents=True, exist_ok=True)

    qmd_config = {
        "enabled": True,
        "auto_index": True,
        "search_mode": "hybrid",
        "models_path": str(get_qmd_models_dir()),
        "install_type": install_type,
        "bin_path": qmd_bin
    }

    with open(config_file, 'w') as f:
        json.dump(qmd_config, f, indent=2)

    print_success(f"Created qmd config: {config_file}")
    print()
    print_info("qmd will auto-download models (~2GB) on first use")
    print_info(f"Models will be cached in: {get_qmd_models_dir()}")

    return True


def cmd_qmd(args):
    """Handle qmd subcommands"""
    subcommand = args.subcommand or 'status'

    if subcommand == 'install':
        # Install both Bun and qmd
        print_info("Installing qmd and dependencies...")
        print()

        # Check if Bun is installed
        if not is_bun_installed():
            if not install_bun():
                print()
                print_error("Failed to install Bun. Cannot continue with qmd installation.")
                return 1
            print()
        else:
            print_success("Bun is already installed")
            print()

        # Install qmd
        if not install_qmd():
            return 1

        print()
        print_success("qmd installation complete!")
        print()
        print_info("Next steps:")
        print_info("  1. Index your cerebrum: samantha-llm memories index")
        print_info("  2. Search memories: samantha-llm memories search <query>")
        return 0

    elif subcommand == 'install-bun':
        # Install only Bun
        if is_bun_installed():
            print_success("Bun is already installed")
            return 0

        if install_bun():
            return 0
        return 1

    elif subcommand == 'status':
        # Show qmd installation status
        print_info("QMD Installation Status:")
        print()

        # Check Bun
        if is_bun_installed():
            try:
                result = subprocess.run(['bun', '--version'], capture_output=True, text=True)
                version = result.stdout.strip()
                print_success(f"Bun: Installed (version {version})")
            except:
                print_success("Bun: Installed")
        else:
            print_error("Bun: Not installed")
            print_info("  Install with: samantha-llm qmd install-bun")

        # Check qmd
        qmd_bin = get_qmd_bin_path()
        if qmd_bin:
            try:
                result = subprocess.run([qmd_bin, '--version'], capture_output=True, text=True)
                version = result.stdout.strip() if result.stdout else 'unknown'
                print_success(f"qmd: Installed (version {version})")
                print_info(f"  Binary: {qmd_bin}")
            except:
                print_success(f"qmd: Installed at {qmd_bin}")

            # Check for models
            models_dir = get_qmd_models_dir()
            if models_dir.exists():
                model_count = len(list(models_dir.glob('*')))
                if model_count > 0:
                    print_success(f"Models: {model_count} models downloaded")
                else:
                    print_warning("Models: Not yet downloaded (will download on first use)")
            else:
                print_warning("Models: Not yet downloaded (will download on first use)")
        else:
            print_error("qmd: Not installed")
            print_info("  Install with: samantha-llm qmd install")

        # Check config
        config_file = get_qmd_config_file()
        if config_file.exists():
            print_success(f"Config: {config_file}")
        else:
            print_warning("Config: Not created")

        print()

        if not is_bun_installed() or not is_qmd_installed():
            print_info("To install qmd, run: samantha-llm qmd install")
        else:
            print_success("qmd is ready to use!")

        return 0

    elif subcommand == 'check':
        # Quick check (exit code 0 if installed, 1 if not)
        if is_qmd_installed():
            print_success("qmd is installed and available")
            return 0
        else:
            print_error("qmd is not installed")
            return 1

    else:
        print_error(f"Unknown qmd subcommand: {subcommand}")
        print_info("Available subcommands:")
        print_info("  install      - Install qmd and dependencies")
        print_info("  install-bun  - Install only Bun runtime")
        print_info("  status       - Show installation status")
        print_info("  check        - Quick check if qmd is available")
        return 1


# ============================================================================
# Memory Commands
# ============================================================================

def get_cerebrum_path():
    """Get path to cerebrum (samantha-llm repo)"""
    return get_repo_dir()


def get_memory_directories():
    """Get list of memory directories to index"""
    cerebrum = get_cerebrum_path()
    return [
        cerebrum / '.ai' / 'short-term-memory' / '.ai',
        cerebrum / '.ai' / 'long-term-memory' / '.ai',
        cerebrum / '.ai' / 'current-tasks' / '.ai',
        cerebrum / '.ai' / 'work-experience' / '.ai',
    ]


def index_cerebrum():
    """Index cerebrum files with qmd"""
    if not is_qmd_installed():
        print_error("qmd is not installed")
        print_info("Install with: samantha-llm qmd install")
        return False

    print_info("Indexing cerebrum files...")
    print()

    # Get memory directories
    memory_dirs = get_memory_directories()

    # Check which directories exist
    existing_dirs = [d for d in memory_dirs if d.exists()]

    if not existing_dirs:
        print_warning("No memory directories found")
        print_info("Memory directories checked:")
        for d in memory_dirs:
            print_info(f"  {d}")
        return False

    print_info(f"Found {len(existing_dirs)} memory directories:")
    for d in existing_dirs:
        file_count = len(list(d.glob('*.md')))
        print_info(f"  {d.name}: {file_count} files")
    print()

    # Get qmd binary path
    qmd_bin = get_qmd_bin_path()
    if not qmd_bin:
        print_error("qmd is not installed")
        print_info("Install with: samantha-llm qmd install")
        return False

    collection_name = "samantha-cerebrum"

    print_info(f"Creating/updating collection: {collection_name}")
    print()

    # Remove existing collection if it exists
    try:
        remove_cmd = [qmd_bin, 'collection', 'remove', collection_name]
        subprocess.run(remove_cmd, capture_output=True, text=True)
        print_info("Removed existing collection")
    except:
        pass  # Collection might not exist yet

    # Index the cerebrum .ai directory once (recursive)
    cerebrum = get_cerebrum_path()
    cerebrum_ai = cerebrum / '.ai'

    print_info(f"Indexing cerebrum directory...")
    print_info(f"  Path: {cerebrum_ai}")
    print_info(f"  Files: {len(list(cerebrum_ai.rglob('*.md')))} markdown files")
    print()

    try:
        cmd = [qmd_bin, 'collection', 'add', str(cerebrum_ai), '--name', collection_name, '--mask', '**/*.md']
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True
        )

        if result.returncode != 0:
            print_error(f"Indexing failed: {result.stderr.strip()}")
            return False

        print_success("Indexed cerebrum successfully!")

    except Exception as e:
        print_error(f"Indexing failed: {e}")
        return False

    # Add context for the collection
    try:
        context_cmd = [
            qmd_bin, 'context', 'add', '/',
            'Personal memory system for Samantha Hartwell, an AI software engineer. Contains memories of past work, technical decisions, and ongoing projects.'
        ]
        subprocess.run(context_cmd, capture_output=True, text=True)
        print_info("Added context metadata")
    except:
        pass  # Context is optional

    print()
    print_success("Cerebrum indexing complete!")
    print_info(f"Collection: {collection_name}")
    print_info("Use: samantha-llm memories search \"<query>\"")

    return True


def search_memories(query, mode='hybrid', format_type='markdown', limit=10, filters=None):
    """Search memories using qmd"""
    qmd_bin = get_qmd_bin_path()
    if not qmd_bin:
        print_error("qmd is not installed")
        print_info("Install with: samantha-llm qmd install")
        return False

    collection_name = "samantha-cerebrum"

    # Build qmd command based on mode
    if mode == 'keyword':
        cmd = [qmd_bin, 'search', query]
    elif mode == 'semantic':
        cmd = [qmd_bin, 'vsearch', query]
    else:  # hybrid (default)
        cmd = [qmd_bin, 'query', query]

    # Add collection filter
    cmd.extend(['-c', collection_name])

    # Add limit
    cmd.extend(['-n', str(limit)])

    # Add format
    if format_type == 'json':
        cmd.append('--json')
    elif format_type == 'plain':
        cmd.append('--text')
    # markdown is default for qmd

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True
        )

        if result.returncode != 0:
            if 'not found' in result.stderr.lower() or 'does not exist' in result.stderr.lower():
                print_error(f"Collection '{collection_name}' not found")
                print_info("Index your cerebrum first: samantha-llm memories index")
            else:
                print_error(f"Search failed: {result.stderr}")
            return False

        # Output results
        output = result.stdout.strip()
        if not output or output == '[]':
            print_warning("No results found")
            print_info(f"Query: {query}")
            print_info(f"Mode: {mode}")
            return True

        # Apply filters if provided (post-processing)
        # For now, just output the results - full filtering can be added later
        print(output)

        return True

    except Exception as e:
        print_error(f"Search failed: {e}")
        return False


def cmd_memories(args):
    """Handle memory commands"""
    subcommand = args.subcommand or 'help'

    if subcommand == 'index':
        # Index cerebrum files
        if index_cerebrum():
            print()
            print_info("Next steps:")
            print_info("  - Search memories: samantha-llm memories search <query>")
            print_info("  - Check status: qmd list samantha-cerebrum")
            return 0
        return 1

    elif subcommand == 'search':
        # Parse remaining arguments for search
        # Get query from args.agent (since we're reusing that field)
        query = args.agent
        if not query:
            print_error("Query required for search")
            print_info("Usage: samantha-llm memories search <query>")
            print_info("Example: samantha-llm memories search 'testing workflows'")
            return 1

        # For now, use defaults (can be enhanced with proper arg parsing later)
        mode = 'hybrid'
        format_type = 'markdown'
        limit = 10

        if search_memories(query, mode, format_type, limit):
            return 0
        return 1

    elif subcommand == 'help' or subcommand not in ['index', 'search']:
        # Show help
        print_info("Memory management commands:")
        print()
        print_info("  samantha-llm memories index           - Index cerebrum files for searching")
        print_info("  samantha-llm memories search <query>  - Search memories semantically")
        print()
        print_info("Examples:")
        print_info("  samantha-llm memories index")
        print_info("  samantha-llm memories search 'testing workflows'")
        print_info("  samantha-llm memories search 'API design patterns'")
        print()
        print_info("Search modes:")
        print_info("  Default: hybrid (keyword + semantic + AI re-ranking)")
        print_info("  Use qmd directly for advanced options (--keyword, --semantic)")
        return 0

    else:
        print_error(f"Unknown memories subcommand: {subcommand}")
        return 1


# ============================================================================
# Persona Commands
# ============================================================================

def cmd_register_persona(args):
    """Register a custom persona"""
    # Parse args: register-persona <name> <file> [--description <desc>]
    name = args.subcommand
    file_path = args.agent

    if not name or not file_path:
        print_error("Usage: samantha-llm register-persona <name> <file> [--description <desc>]")
        print_info("")
        print_info("Examples:")
        print_info("  samantha-llm register-persona tax-accountant ./my-persona.md")
        print_info("  samantha-llm register-persona artist ~/personas/artist.md --description 'Creative art critic'")
        return 1

    # Validate persona name
    is_valid, error = validate_persona_name(name)
    if not is_valid:
        print_error(f"Invalid persona name: {error}")
        return 1

    # Check if file exists
    source_path = Path(file_path).expanduser().resolve()
    if not source_path.exists():
        print_error(f"Persona file not found: {file_path}")
        return 1

    # Read config
    config = ensure_config_migrated()
    if not config:
        print_error("Config not found. Run 'samantha-llm install' first.")
        return 1

    # Check if persona already exists
    if name in config.get('personas', {}):
        persona = config['personas'][name]
        if persona.get('official'):
            print_error(f"Cannot overwrite official persona: {name}")
            return 1

        print_warning(f"Persona '{name}' already exists")
        response = input("Overwrite? (y/N): ").strip().lower()
        if response != 'y':
            print_info("Cancelled.")
            return 0

    # Create personas directory
    personas_dir = get_personas_dir()
    personas_dir.mkdir(parents=True, exist_ok=True)

    # Copy file to personas directory
    dest_path = personas_dir / f"{name}.md"
    try:
        shutil.copy2(source_path, dest_path)
    except Exception as e:
        print_error(f"Failed to copy persona file: {e}")
        return 1

    # Register in config
    description = args.description if hasattr(args, 'description') and args.description else f"Custom persona: {name}"

    if 'personas' not in config:
        config['personas'] = {}

    config['personas'][name] = {
        'type': 'custom',
        'file': str(dest_path),
        'description': description,
        'registered_at': datetime.now().isoformat()
    }

    # Save config
    if not write_config(config):
        print_error("Failed to save config")
        return 1

    print_success(f"Registered persona: {name}")
    print_info(f"  File: {dest_path}")
    print_info(f"  Description: {description}")
    print()
    print_info("Use with: samantha-llm start --persona {name}")

    return 0


def cmd_personas(args):
    """List personas or set default"""
    # Check for --set-default flag
    set_default = args.default_agent if hasattr(args, 'default_agent') else None

    # Read config
    config = ensure_config_migrated()
    if not config:
        print_error("Config not found. Run 'samantha-llm install' first.")
        return 1

    if set_default:
        # Set default persona
        if 'personas' not in config or set_default not in config['personas']:
            print_error(f"Persona not found: {set_default}")
            print_info("Available personas:")
            for name, _ in list_personas(config):
                print_info(f"  - {name}")
            return 1

        config['default_persona'] = set_default

        if not write_config(config):
            print_error("Failed to save config")
            return 1

        print_success(f"Default persona set to: {set_default}")
        return 0

    # List personas
    personas = list_personas(config)

    if not personas:
        print_info("No personas registered.")
        print_info("Register a persona with: samantha-llm register-persona <name> <file>")
        return 0

    default_persona = config.get('default_persona')

    print_info("Available personas:")
    print()

    for name, persona in personas:
        is_default = (name == default_persona)
        is_builtin = persona.get('type') == 'builtin'

        # Format line
        prefix = "  * " if is_default else "    "
        suffix = " [builtin]" if is_builtin else " [custom]"
        if is_default:
            suffix += " (default)"

        description = persona.get('description', '')

        print_info(f"{prefix}{name}{suffix}")
        if description:
            print_info(f"      {description}")

    print()
    print_info("Commands:")
    print_info("  samantha-llm personas --set-default <name>  - Set default persona")
    print_info("  samantha-llm start --persona <name>         - Use specific persona")

    return 0


def cmd_unregister_persona(args):
    """Unregister a custom persona"""
    name = args.subcommand

    if not name:
        print_error("Usage: samantha-llm unregister-persona <name>")
        print_info("")
        print_info("Example:")
        print_info("  samantha-llm unregister-persona tax-accountant")
        return 1

    # Read config
    config = ensure_config_migrated()
    if not config:
        print_error("Config not found.")
        return 1

    # Check if persona exists
    if 'personas' not in config or name not in config['personas']:
        print_error(f"Persona not found: {name}")
        return 1

    persona = config['personas'][name]

    # Cannot unregister builtin personas
    if persona.get('official') or persona.get('type') == 'builtin':
        print_error(f"Cannot unregister official persona: {name}")
        return 1

    # Cannot unregister default persona
    if config.get('default_persona') == name:
        print_error(f"Cannot unregister default persona: {name}")
        print_info("Set a different default first with: samantha-llm personas --set-default <name>")
        return 1

    # Confirm deletion
    print_warning(f"This will permanently delete persona: {name}")
    response = input("Continue? (y/N): ").strip().lower()
    if response != 'y':
        print_info("Cancelled.")
        return 0

    # Delete file if it exists
    persona_file = Path(persona['file']).expanduser()
    if persona_file.exists():
        try:
            persona_file.unlink()
            print_info(f"Deleted file: {persona_file}")
        except Exception as e:
            print_warning(f"Failed to delete file: {e}")

    # Remove from config
    del config['personas'][name]

    if not write_config(config):
        print_error("Failed to save config")
        return 1

    print_success(f"Unregistered persona: {name}")

    return 0


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(
        prog='samantha-llm',
        description='Samantha Hartwell LLM Management Tool',
        add_help=False
    )
    parser.add_argument('command', nargs='?', default='help',
                        choices=['install', 'uninstall', 'status', 'link', 'unlink', 'setup', 'agents', 'start', 'qmd', 'memories', 'subconscious', 'personas', 'register-persona', 'unregister-persona', 'help', 'version'],
                        help='Command to execute')
    parser.add_argument('subcommand', nargs='?', default=None,
                        help='Subcommand (for qmd command)')
    parser.add_argument('agent', nargs='?', default=None,
                        help='Agent name (for start command)')
    parser.add_argument('--default', dest='default_agent', metavar='AGENT',
                        help='Set default agent/persona (for setup/personas command)')
    parser.add_argument('--persona', dest='persona', metavar='NAME',
                        help='Persona to use (for start command)')
    parser.add_argument('--description', dest='description', metavar='DESC',
                        help='Description for persona (for register-persona command)')
    parser.add_argument('--help', '-h', action='store_true',
                        help='Show help message')

    args = parser.parse_args()

    # Handle --help flag
    if hasattr(args, 'help') and args.help:
        return cmd_help(args)

    commands = {
        'install': cmd_install,
        'uninstall': cmd_uninstall,
        'status': cmd_status,
        'link': cmd_link,
        'unlink': cmd_unlink,
        'setup': cmd_setup,
        'agents': cmd_agents,
        'start': cmd_start,
        'qmd': cmd_qmd,
        'memories': cmd_memories,
        'subconscious': cmd_subconscious,
        'personas': cmd_personas,
        'register-persona': cmd_register_persona,
        'unregister-persona': cmd_unregister_persona,
        'help': cmd_help,
        'version': cmd_version,
    }

    return commands[args.command](args)


if __name__ == '__main__':
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print()
        print_warning("Cancelled by user")
        sys.exit(130)
    except Exception as e:
        print_error(f"Unexpected error: {e}")
        sys.exit(1)
